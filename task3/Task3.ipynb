{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from biosppy.signals.ecg import extract_heartbeats\n",
    "from biosppy.signals.ecg import ecg\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import norm\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_train.csv')\n",
    "y = pd.read_csv('y_train.csv')\n",
    "\n",
    "X = X.drop(['id'],axis=1)\n",
    "y = y.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0.0)\n",
    "X.at[5116,'x17978'] = 0.0\n",
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyVar(signal,show=False):\n",
    "    signal = removeStartEnd(signal)\n",
    "    ecgResults = ecg(signal,sampling_rate=300, show=False)\n",
    "    templates = np.swapaxes(ecgResults[4],1,0)\n",
    "    \n",
    "    # Summed variance over whole tamplate scaled by Median peak amplitude\n",
    "    peakAmplitudes = []\n",
    "    for k in ecgResults[2]:\n",
    "        peakAmplitudes.append(ecgResults[1][k])\n",
    "    amplitudeMedian = np.median(np.array(peakAmplitudes))\n",
    "    scaledTemplates = templates/amplitudeMedian\n",
    "    sumVar = np.sum(scaledTemplates.var(axis=1))\n",
    "    \n",
    "    return sumVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStartEnd(signal):\n",
    "    end = np.count_nonzero(signal)\n",
    "    start = 0\n",
    "    if (type(signal) == type(np.array([2]))):\n",
    "        return signal[start+300:end-300]\n",
    "    return signal[start+300:end-300].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQs(ecgResults):\n",
    "    '''\n",
    "    :return qsTime: timepoints of Q in the whole time\n",
    "            qsValue: value of Q's amplitude\n",
    "    '''\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    qsTime = []\n",
    "    qsValue = []\n",
    "    \n",
    "    for peak in ecgResults[2]:\n",
    "        # Heartbeat is at timestamp 60 (=time 0)\n",
    "        numChances = 2\n",
    "        currValue = ecgResults[1][peak]\n",
    "        nextValue = ecgResults[1][peak]\n",
    "        foundMinimum = ecgResults[1][peak]\n",
    "        foundMinimumIndex = peak\n",
    "        \n",
    "        i = peak-1\n",
    "        while (nextValue <= currValue or numChances >= 0):\n",
    "            # update\n",
    "            currValue = nextValue\n",
    "            nextValue = ecgResults[1][i]\n",
    "            if (foundMinimum >= nextValue):\n",
    "                foundMinimum = nextValue\n",
    "                foundMinimumIndex = i\n",
    "            i = i-1\n",
    "            if (currValue < nextValue):\n",
    "                numChances -= 1\n",
    "            \n",
    "        qsTime.append(foundMinimumIndex)\n",
    "        qsValue.append(foundMinimum)\n",
    "        \n",
    "    return [qsTime, qsValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSs(ecgResults):\n",
    "    sTime = []\n",
    "    sValue = []\n",
    "    \n",
    "    for peak in ecgResults[2]:\n",
    "        # Heartbeat is at timestamp 60 (=time 0)\n",
    "        numChances = 2\n",
    "        currValue = ecgResults[1][peak]\n",
    "        nextValue =ecgResults[1][peak]\n",
    "        foundMinimum = ecgResults[1][peak]\n",
    "        foundMinimumIndex = peak\n",
    "        \n",
    "        i = peak+1\n",
    "        while (nextValue <= currValue or numChances >= 0):\n",
    "            # update\n",
    "            currValue = nextValue\n",
    "            nextValue = ecgResults[1][i]\n",
    "            if (foundMinimum >= nextValue):\n",
    "                foundMinimum = nextValue\n",
    "                foundMinimumIndex = i\n",
    "            i = i+1\n",
    "            if (currValue < nextValue):\n",
    "                numChances -= 1\n",
    "            \n",
    "        sTime.append(foundMinimumIndex)\n",
    "        sValue.append(foundMinimum)\n",
    "\n",
    "        \n",
    "    return [sTime, sValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAmplitudes(signal,points,show=False):\n",
    "    amps = []\n",
    "    for p in points:\n",
    "        amps.append(signal[p])\n",
    "    \n",
    "    if (show):\n",
    "        plt.plot(signal)\n",
    "        plt.plot(points,amps)\n",
    "    return amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQsNormal(signal, peakTimes):\n",
    "    qsTime = []\n",
    "    qsValue = []\n",
    "        \n",
    "    for peak in peakTimes:\n",
    "        numChances = 2\n",
    "        currValue = signal[peak]\n",
    "        nextValue = signal[peak]\n",
    "        foundMinimum = signal[peak]\n",
    "        foundMinimumIndex = peak\n",
    "        \n",
    "        i = peak-1\n",
    "        while (nextValue <= currValue or numChances >= 0):\n",
    "            if(i==-1):\n",
    "                foundMinimumIndex = i+1\n",
    "                foundMinimum = nextValue\n",
    "                break\n",
    "            # update\n",
    "            currValue = nextValue\n",
    "            nextValue = signal[i]\n",
    "            if (foundMinimum >= nextValue):\n",
    "                foundMinimum = nextValue\n",
    "                foundMinimumIndex = i\n",
    "            i = i-1\n",
    "            if (currValue < nextValue):\n",
    "                numChances -= 1\n",
    "                \n",
    "        qsTime.append(foundMinimumIndex)\n",
    "        qsValue.append(foundMinimum)\n",
    "        \n",
    "    return [qsTime, qsValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSsNormal(signal, peakTimes):\n",
    "    sTime = []\n",
    "    sValue = []\n",
    "    \n",
    "    for peak in peakTimes:\n",
    "        # Heartbeat is at timestamp 60 (=time 0)\n",
    "        numChances = 2\n",
    "        currValue = signal[peak]\n",
    "        nextValue = signal[peak]\n",
    "        foundMinimum = signal[peak]\n",
    "        foundMinimumIndex = peak\n",
    "        \n",
    "        i = peak+1\n",
    "        while (nextValue <= currValue or numChances >= 0):\n",
    "            if(i==17979):\n",
    "                foundMinimumIndex = i-1\n",
    "                foundMinimum = nextValue\n",
    "                break\n",
    "            # update\n",
    "            currValue = nextValue\n",
    "            nextValue = signal[i]\n",
    "            if (foundMinimum >= nextValue):\n",
    "                foundMinimum = nextValue\n",
    "                foundMinimumIndex = i\n",
    "            i = i+1\n",
    "            if (currValue < nextValue):\n",
    "                numChances -= 1\n",
    "            \n",
    "        sTime.append(foundMinimumIndex)\n",
    "        sValue.append(foundMinimum)\n",
    "\n",
    "        \n",
    "    return [sTime, sValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile(arr,percent):\n",
    "    '''\n",
    "    param: percent (should be between 0 and 1) how much you want to keep\n",
    "    '''\n",
    "    if(type(arr) != type(np.array(arr))):\n",
    "        arr = np.array(arr)\n",
    "    length = arr.shape[0]\n",
    "    if(length < 2):\n",
    "        return arr\n",
    "    numOuts = math.ceil(length*(1-percent))\n",
    "    median = np.median(arr)\n",
    "    dists = []\n",
    "    dists2 = []\n",
    "    for i in range(0,length):\n",
    "        dists.append(np.absolute(arr[i]-median))\n",
    "        dists2.append(np.absolute(arr[i]-median))\n",
    "    dists = np.array(dists)\n",
    "    dists.sort()\n",
    "    outs = dists[length-numOuts:length]\n",
    "    minDistExclusive = np.min(outs)\n",
    "    res = []\n",
    "    for i in range(0,length):\n",
    "        if(dists2[i] < minDistExclusive):\n",
    "            res.append(arr[i])\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medianvar(templates):\n",
    "    arr = np.swapaxes(templates,1,0)\n",
    "    variances = []\n",
    "    for i in range(0,arr.shape[0]):\n",
    "        variances.append(np.var(medianGaps(arr[i])))\n",
    "    varSum = 0\n",
    "    for var in variances:\n",
    "        varSum += var\n",
    "    return varSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medianGaps(arr):\n",
    "    median = np.median(arr)\n",
    "    gaps = []\n",
    "    for i in range(0,arr.shape[0]):\n",
    "        gaps.append(np.absolute(median - arr[i]))\n",
    "    return np.array(gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaps(arr):\n",
    "    if(type(arr) != type(np.array(arr))):\n",
    "        arr = np.array(arr)\n",
    "    length = arr.shape[0]\n",
    "    if (length == 2):\n",
    "        return np.absolute(arr[0]-arr[1])\n",
    "    gaps = []\n",
    "    prev = arr[0]\n",
    "    for i in range(1,length):\n",
    "        gaps.append(np.absolute(prev-arr[i]))\n",
    "        prev = arr[i]\n",
    "    return np.array(gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap To correct Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "invs = []\n",
    "fract = []\n",
    "for i in range(0, X.shape[0]):\n",
    "    var = onlyVar(X.iloc[i])\n",
    "    varI = onlyVar(X.iloc[i]*(-1))\n",
    "    if (varI < var):\n",
    "        invs.append(-1)\n",
    "        fract.append(var/varI)\n",
    "    else:\n",
    "        invs.append(1)\n",
    "        fract.append(varI/var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X.mul(np.array(invs),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Messfehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delMessfehlerMinimum(signal, mul, margin):\n",
    "    if(type(signal) != type(np.array([1]))):\n",
    "        signal = signal.to_numpy()\n",
    "        \n",
    "    ecgResults = ecg(signal,sampling_rate=300,show=False)\n",
    "    Rs = ecgResults[2]\n",
    "    Qs = getQs(ecgResults)\n",
    "    Ss = getSs(ecgResults)\n",
    "\n",
    "    #amps = getAmplitudes(signal,Rs, show)\n",
    "    Samps = getAmplitudes(signal,Ss[0])\n",
    "    Qamps = getAmplitudes(signal,Qs[0])\n",
    "    \n",
    "    mi = min(np.median(Samps),np.median(Qamps),-300)\n",
    "    margin = margin\n",
    "    returnSignal = signal\n",
    "\n",
    "    # Take all number which are siginificantely bigger than the quartile minimum\n",
    "    timesmi = []\n",
    "    for i in range(0,signal.shape[0]):\n",
    "        if (signal[i] < mi*mul):\n",
    "            timesmi.append(i)\n",
    "\n",
    "    if (len(timesmi)==0):\n",
    "        return returnSignal\n",
    "    \n",
    "    clusters = []\n",
    "    cluster = [timesmi[0]]\n",
    "\n",
    "    for i in range(1,len(timesmi)):\n",
    "        if (timesmi[i]-timesmi[i-1]>= 100):\n",
    "            clusters.append(cluster)\n",
    "            cluster = [timesmi[i]]\n",
    "        else:\n",
    "            cluster.append(timesmi[i])\n",
    "    clusters.append(cluster)\n",
    "                \n",
    "    # many clusters: Then probaly class 2, and we only delete culters with more than 30 entries\n",
    "    corr = 0 # Since we slice the indexes change, so we need to correct them\n",
    "    if (len(clusters) >= 5):\n",
    "        amps = []\n",
    "        for cluster in clusters:\n",
    "            ampclusters = []\n",
    "            for el in cluster:\n",
    "                ampclusters.append(signal[el])\n",
    "            amps.append(np.min(np.array(ampclusters)))\n",
    "        median = np.median(np.array(amps))\n",
    "        for cluster in clusters:\n",
    "            ampclusters = []\n",
    "            for el in cluster:\n",
    "                ampclusters.append(returnSignal[el-corr])\n",
    "            if (np.min(np.array(ampclusters)) < median*1.2):\n",
    "                if(cluster[0]-1-margin-corr < 0):\n",
    "                    continue\n",
    "                returnSignal = np.concatenate((returnSignal[0:cluster[0]-1-margin-corr],returnSignal[cluster[-1]-corr+margin:]))\n",
    "                corr += (cluster[-1]-cluster[0])+1+2*margin  # The plus 2*margin becuase we exluce [a-margin,b+margin] instead of [a,b] \n",
    "    # Only a few clusters. We assume everything i\n",
    "    else:\n",
    "        for cluster in clusters:\n",
    "            if(cluster[0]-1-margin-corr < 0):\n",
    "                continue\n",
    "            returnSignal = np.concatenate((returnSignal[0:cluster[0]-1-margin-corr],returnSignal[cluster[-1]-corr+margin:]))\n",
    "            corr += (cluster[-1]-cluster[0])+1+2*margin  # The plus 2*margin becuase we exluce [a-margin,b+margin] instead of [a,b] \n",
    "    ret = np.zeros(17979)\n",
    "    for i in range(len(returnSignal)):\n",
    "        ret[i]=returnSignal[i]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delMessfehlerMaximum(signal, mul, margin):\n",
    "    if(type(signal) != type(np.array([1]))):\n",
    "        signal = signal.to_numpy()\n",
    "    \n",
    "    ecgResults = ecg(signal,sampling_rate=300,show=False)\n",
    "    Rs = ecgResults[2]\n",
    "    Ramps = getAmplitudes(signal,Rs)    \n",
    "\n",
    "    margin = margin\n",
    "    ma = np.median(Ramps) # Take median of peaks\n",
    "    returnSignal = signal\n",
    "\n",
    "    # Take all number which are siginificantely bigger than the quartile minimum\n",
    "    timesmi = []\n",
    "    for i in range(0,signal.shape[0]):\n",
    "        if (signal[i] > ma*mul):\n",
    "            timesmi.append(i)\n",
    "                        \n",
    "    if (len(timesmi)==0):\n",
    "        return returnSignal\n",
    "    \n",
    "    clusters = []\n",
    "    cluster = [timesmi[0]]\n",
    "\n",
    "    for i in range(1,len(timesmi)):\n",
    "        if (timesmi[i]-timesmi[i-1]>= 100):\n",
    "            clusters.append(cluster)\n",
    "            cluster = [timesmi[i]]\n",
    "        else:\n",
    "            cluster.append(timesmi[i])\n",
    "    clusters.append(cluster)\n",
    "    \n",
    "    # many clusters: Then probaly class 2, and we only delete culters with more than 30 entries\n",
    "    corr = 0 # Since we slice the indexes change, so we need to correct them\n",
    "    if (len(clusters) >= 5):\n",
    "        amps = []\n",
    "        for cluster in clusters:\n",
    "            ampclusters = []\n",
    "            for el in cluster:\n",
    "                ampclusters.append(signal[el])\n",
    "            amps.append(np.max(np.array(ampclusters)))\n",
    "        median = np.median(np.array(amps))\n",
    "        for cluster in clusters:\n",
    "            ampclusters = []\n",
    "            for el in cluster:\n",
    "                ampclusters.append(returnSignal[el-corr])\n",
    "            if (np.max(np.array(ampclusters)) > median*1.2):\n",
    "                if(cluster[0]-1-margin-corr < 0):\n",
    "                    continue\n",
    "                returnSignal = np.concatenate((returnSignal[0:cluster[0]-1-margin-corr],returnSignal[cluster[-1]-corr+margin:]))\n",
    "                corr += (cluster[-1]-cluster[0])+1+2*margin # The plus 2*margin becuase we exluce [a-margin,b+margin] instead of [a,b] \n",
    "    # Only a few clusters. We assume everything i\n",
    "    else:\n",
    "        for cluster in clusters:\n",
    "            if(cluster[0]-1-margin-corr < 0):\n",
    "                continue\n",
    "            returnSignal = np.concatenate((returnSignal[0:cluster[0]-1-margin-corr],returnSignal[cluster[-1]-corr+margin:]))\n",
    "            corr += (cluster[-1]-cluster[0])+1+2*margin  # The plus 2*margin becuase we exluce [a-margin,b+margin] instead of [a,b] \n",
    "    ret = np.zeros(17979)\n",
    "    for i in range(len(returnSignal)):\n",
    "        ret[i]=returnSignal[i]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,X_corr.shape[0]):\n",
    "    signal = X_corr.iloc[i]\n",
    "    newsignal = delMessfehlerMinimum(signal,1.7,50)\n",
    "    newsignal = delMessfehlerMaximum(newsignal,1.7,50)\n",
    "    X_corr.iloc[i] = newsignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no3 = X_corr[y.y != 3]\n",
    "y_no3 = y[y.y != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nici Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftWindow(wSize,signal,show=False):\n",
    "    ecgResults = ecg(signal,sampling_rate=300, show=show)\n",
    "    templates = ecgResults[4]\n",
    "\n",
    "    # Summed variance over whole tamplate scaled by Median peak amplitude\n",
    "    peakAmplitudes = []\n",
    "    for k in ecgResults[2]:\n",
    "        peakAmplitudes.append(ecgResults[1][k])\n",
    "    amplitudeMedian = np.median(np.array(peakAmplitudes))\n",
    "    templates = templates/amplitudeMedian\n",
    "\n",
    "    wSize = min(wSize, templates.shape[0])\n",
    "    window = templates[0:wSize]\n",
    "    #print(scaledTemplates.shape)\n",
    "    winStart = ecgResults[2][0]\n",
    "    winEnd = ecgResults[2][wSize-1] \n",
    "    minVar = medianvar(window)\n",
    "    \n",
    "    for i in range(wSize+1, templates.shape[0]):\n",
    "        if (medianvar(templates[i-wSize:i])<minVar):\n",
    "            window = templates[i-wSize:i]\n",
    "            winStart = ecgResults[2][i-1-wSize]\n",
    "            winEnd = ecgResults[2][i]\n",
    "            minVar = medianvar(templates[i-wSize:i])\n",
    "    \n",
    "    windowMean = np.median(window, axis = 0)\n",
    "    windowVar = np.var(window, axis = 0)\n",
    "    \n",
    "    prTemplates = []\n",
    "    for t in templates:\n",
    "        prTemp = []\n",
    "        for i in range(len(t)):\n",
    "            prTemp.append(min(1,norm.pdf(x = t[i], loc = windowMean[i],scale = windowVar[i])))\n",
    "        prTemplates.append(np.sum(prTemp))\n",
    "\n",
    "    return [minVar, winStart, winEnd, window, prTemplates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findP(signal):\n",
    "    t = np.argmax(signal[0:45])\n",
    "    #plt.scatter(t,signal[t],color='red')\n",
    "    return t\n",
    "\n",
    "def findQ(signal):\n",
    "    t = np.argmin(signal[25:60])+25\n",
    "    #plt.scatter(t,signal[t],color='red')\n",
    "    return t\n",
    "\n",
    "def findR(signal):\n",
    "    t = 60\n",
    "    #plt.scatter(t,signal[t],color='red')\n",
    "    return t\n",
    "\n",
    "def findS(signal):\n",
    "    t = np.argmin(signal[60:110])+60\n",
    "    #plt.scatter(t,signal[t],color='red')\n",
    "    return t\n",
    "\n",
    "def findT(signal):\n",
    "    t = np.argmax(signal[75:150])+75\n",
    "    #plt.scatter(t,signal[t],color='red')\n",
    "    return t\n",
    "\n",
    "def findTstart(signal, T):\n",
    "    mi = signal[T]\n",
    "    miT = T\n",
    "    k = T\n",
    "    numChances = 2\n",
    "    while((mi > signal[k] and signal[k] >= -0.05) or numChances >= 0):\n",
    "        if(mi > signal[k] and signal[k] >= -0.05):\n",
    "            mi = signal[k]\n",
    "            miT = k\n",
    "        else:\n",
    "            numChances -= 1\n",
    "        k -= 1\n",
    "    #plt.scatter(miT,mi,color='green')\n",
    "    return miT\n",
    "\n",
    "def findTend(signal, T):\n",
    "    t = np.argmin(signal[T:175])+T\n",
    "    #plt.scatter(t,signal[t],color='green')\n",
    "    return t\n",
    "\n",
    "def findSTelbow(signal, S):\n",
    "    k = S+3\n",
    "    t = S+3\n",
    "    numChances = 3\n",
    "    currA = signal[k]\n",
    "    nextA = signal[k+1]\n",
    "    trend = (nextA - currA)*180\n",
    "    while(trend > 1 or numChances >= 0):\n",
    "        if (trend < 1):\n",
    "            numChances -= 1\n",
    "        else:\n",
    "            t+= 1\n",
    "        k+= 1\n",
    "        trend = (signal[k+1] - signal[k])*180\n",
    "    #plt.scatter(k,signal[k],color='black')\n",
    "    return k\n",
    "\n",
    "def QRTrendChange(signal, Q, R):\n",
    "    trends=[]\n",
    "    for k in range(Q,R):\n",
    "        trends.append((signal[k+1] - signal[k])*180)\n",
    "    trendCurve = np.array(trends)\n",
    "    try:\n",
    "        trendCurve = savgol_filter(trendCurve, 11, 3)\n",
    "    except: \n",
    "        try:\n",
    "            trendCurve = savgol_filter(trendCurve, 9, 3)\n",
    "        except:\n",
    "            try:\n",
    "                trendCurve = savgol_filter(trendCurve, 7, 3)\n",
    "            except: trendCurve = trendCurve\n",
    "\n",
    "    maxs = []\n",
    "    for j in range(1,trendCurve.shape[0]-1):\n",
    "        if(trendCurve[j-1] < trendCurve[j] and trendCurve[j+1] < trendCurve[j]\n",
    "          and signal[j+Q] and signal[j+Q] and trendCurve[j]>3):\n",
    "            maxs.append(j)\n",
    "    \n",
    "    if(len(maxs) < 2):\n",
    "        return 0\n",
    "    \n",
    "    length = len(maxs)\n",
    "    for i in range(1,length):\n",
    "        if (maxs[i]-maxs[i-1] >= 3):\n",
    "            return 1\n",
    "        \n",
    "    return 0\n",
    "\n",
    "def varClusters(templates, P, R):\n",
    "    swaped = np.swapaxes(templates,1,0)\n",
    "    \n",
    "    # 1 cluster\n",
    "    sumVar = np.sum(swaped[P:R].var(axis=1))\n",
    "    \n",
    "    # 2 clusters\n",
    "    qrSignal = swaped[P:R]\n",
    "    var = 0\n",
    "    for i in range(0,qrSignal.shape[1]):\n",
    "        numbers = qrSignal[i]\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(numbers.reshape(-1,1))\n",
    "        labels = kmeans.labels_\n",
    "        c0 = []\n",
    "        c1 = []\n",
    "        for k in range(0,numbers.shape[0]):\n",
    "            if (labels[k] == 0):\n",
    "                c0.append(numbers[k])\n",
    "            else:\n",
    "                c1.append(numbers[k])\n",
    "        var = var + np.var(np.array(c0)) + np.var(np.array(c1))\n",
    "      \n",
    "    return [sumVar,var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4947/4947 [1:21:35<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "niciFeatures = []\n",
    "j = 0\n",
    "\n",
    "for i,row in tqdm(X_no3.iterrows(), total=X_no3.shape[0],position=0, leave=True):    \n",
    "    # Appply sliding window\n",
    "    var, start, end, templates, pr = shiftWindow(8,row)\n",
    "    \n",
    "    # find P,Q,R etc.\n",
    "    swaped = np.swapaxes(templates,1,0)\n",
    "    signal = []\n",
    "    for i in range(0,180):\n",
    "        signal.append(np.median(swaped[i]))\n",
    "    signal = np.array(signal)\n",
    "    P = findP(signal)\n",
    "    Q = findQ(signal)\n",
    "    R = findR(signal)\n",
    "    S = findS(signal)\n",
    "    T = findT(signal)\n",
    "    Ts = findTstart(signal, T)\n",
    "    Te = findTend(signal, T)\n",
    "    STelbow = findSTelbow(signal,S)\n",
    "    mins = QRTrendChange(signal, Q, R)\n",
    "    var1, var2 =  varClusters(templates,P, R-3)\n",
    "    \n",
    "    a = [var, P, signal[P], Q, signal[Q], signal[R], S, signal[S], \n",
    "        T, signal[T], Ts, signal[Ts], Te, signal[Te],\n",
    "        STelbow, signal[STelbow], mins, var1, var2]\n",
    "    \n",
    "    niciFeatures.append(a)\n",
    "    \n",
    "niciFeatures = np.array(niciFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfeatures(signal):\n",
    "    # For the preprocessed Signal cal sumVar\n",
    "    signal2 = removeStartEnd(signal)\n",
    "    ecgResults = ecg(signal2,sampling_rate=300, show=False)\n",
    "    templates = np.swapaxes(ecgResults[4],1,0) #This is adjusted signal\n",
    "    peakAmplitudes = []\n",
    "    for k in ecgResults[2]:\n",
    "        peakAmplitudes.append(ecgResults[1][k])\n",
    "    amplitudeMedian = np.median(np.array(peakAmplitudes))\n",
    "    scaledTemplates = templates/amplitudeMedian\n",
    "    sumVar = np.sum(scaledTemplates.var(axis=1))\n",
    "    \n",
    "    # Feature 0\n",
    "    nvar = sumVar # Scaled (by R-Median) Variance of the preprocessed ECG Signal\n",
    "    \n",
    "    \n",
    "    # Get the Qs and Ss\n",
    "    [Qtime, Qs] = getQsNormal(signal2,ecgResults[2]) # [QTime, QValue], get value&Amplitude of Q\n",
    "    [Stime, Ss] = getSsNormal(signal2,ecgResults[2]) # [sTime, sValue], get value&Amplitude of S\n",
    "    \n",
    "    #Features more for finding Class 1:\n",
    "    diffR = ecgResults[2]\n",
    "    diffR = diffR[1:] - diffR[:(len(diffR)-1)]\n",
    "    Rvar = np.var(diffR) #Variance of R timepoint-difference\n",
    "    RIQA = np.quantile(diffR,0.75) - np.quantile(diffR,0.25) #IQA of R timepoint-difference\n",
    "    diff = np.array(Qtime)\n",
    "    diff = diff[1:] - diff[:(len(diff)-1)]\n",
    "    QIQA = np.quantile(diff,0.75) - np.quantile(diff,0.25) #IQA of Q timepoint-difference\n",
    "    diff = np.array(Stime)\n",
    "    diff = diff[1:] - diff[:(len(diff)-1)]\n",
    "    SIQA = np.quantile(diff,0.75) - np.quantile(diff,0.25) #IQA of S timepoint-difference\n",
    "    \n",
    "    #To eliminate X[22] bzw class 2 with Rpeak and high T that gets recognized as R -> Take difference of difference\n",
    "    #-> If R-diff (in t) is big-small-big-small -> We find it this way\n",
    "    diffofdiffR = np.absolute(diffR[1:] - diffR[:(len(diffR)-1)])\n",
    "    diffofdiffRmed = np.median(diffofdiffR)\n",
    "    \n",
    "    #Include heartrate variability: Proposed in slide and maybe is better version of R-Variance\n",
    "    if ecgResults[6].size == 0: #If ecg doesn't calculate a heartbeat, just set the variables to 0\n",
    "        heartratevar = 0\n",
    "        heartrateIQA = 0\n",
    "        heartratemed = 80\n",
    "    else:\n",
    "        heartratevar = ecgResults[6].var(axis=0)\n",
    "        heartrateIQA = np.quantile(ecgResults[6],0.75) - np.quantile(ecgResults[6],0.25)\n",
    "        heartratemed = np.median(ecgResults[6])\n",
    "    \n",
    "    #Features more for differentiating Class 0&2:\n",
    "    #Include robust amplitude(median) of Q,R,S of preprocessed signal (Because of slides)\n",
    "    #Note that I leave Ramp, while I scale Qamp&Samp by Ramp to make it comparable across samples with diff. amplitudes\n",
    "    qsTime, qsValue = getQs(ecgResults)\n",
    "    ssTime, ssValue = getSs(ecgResults)\n",
    "    Rs = ecgResults[1][ecgResults[2]]\n",
    "    Ramp = np.median(Rs)\n",
    "    Qamp = np.median(qsValue)/Ramp\n",
    "    Samp = np.median(ssValue)/Ramp\n",
    "    \n",
    "    \n",
    "    #Include the robust difference of Q-S time interval and Q-S amplitude(of preprocessed signal)\n",
    "    QRS = np.array(ssTime) - np.array(qsTime)\n",
    "    QRSmed = np.median(QRS) #Recommended in tutorial, median of distance from Q to S\n",
    "    QSampdiff = np.array(qsValue) - np.array(ssValue) #amplitude of q-s (should be mildly positive)\n",
    "    QSampdiffmed = np.median(QSampdiff)/Ramp #Robust Difference in amplitude of Q and S scaled by Ramp\n",
    "    QSampdiffIQA = np.quantile(QSampdiff,0.9) - np.quantile(QSampdiff,0.1) #for Nr.3 where it varies\n",
    "    \n",
    "    #Find T as the maximum of values between S and next Q to find this anomaly in Class 2. \n",
    "    Rpeaks = ecgResults[2]\n",
    "    Tpeaks = [None]*(np.shape(ecgResults[2])[0]-1)\n",
    "\n",
    "    for i in range(np.shape(ecgResults[2])[0]-1): #Find maximum of values between S and Q of next heartbeat -> T\n",
    "        if ssTime[i]>=qsTime[i+1]: #For 52 it has two R without a S inbetween -> gives error.\n",
    "            if i == 0: #If q(t+1) and s(t) are the same for the first R peak -> Set to 0 bzw make it an outlier\n",
    "                Tpeaks[i] = 0\n",
    "            else:\n",
    "                Tpeaks[i] = Tpeaks[i-1]\n",
    "        else:       \n",
    "            Tpeaks[i] = max(ecgResults[1][ssTime[i]:qsTime[i+1]]) \n",
    "    Tamp = np.median(Tpeaks)/Ramp\n",
    "    \n",
    "    #Compare size of S with size of T scaled by R\n",
    "    STdiff = Tpeaks - np.array(ssValue[:np.shape(ecgResults[2])[0]-1])\n",
    "    STdiffmed = np.median(STdiff)/Ramp\n",
    "    \n",
    "    #Most promising features in my head(w/o testing by ML): \n",
    "    #For finding Class 1: RIQA(combined with DiffofdiffRmed)\n",
    "    #For finding Class 2: QSampdiffmed,Tamp\n",
    "\n",
    "    return [RIQA, Rvar, diffofdiffRmed, QIQA, SIQA, heartratevar, heartrateIQA, \n",
    "            heartratemed, Ramp, Qamp, Samp, QRSmed, QSampdiffmed, QSampdiffIQA, Tamp, STdiffmed, nvar]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4947/4947 [02:33<00:00, 32.32it/s]\n"
     ]
    }
   ],
   "source": [
    "moFeatures = []\n",
    "\n",
    "for i,row in tqdm(X_no3.iterrows(), total=X_no3.shape[0],position=0, leave=True): \n",
    "    moFeatures.append(classfeatures(row))\n",
    "    \n",
    "moFeatures = np.array(moFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRV features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pyhrv.hrv as hrv\n",
    "import pyhrv.tools as tools\n",
    "import pyhrv.time_domain as td\n",
    "import pyhrv.nonlinear as nl\n",
    "import pyhrv.frequency_domain as fd\n",
    "\n",
    "\n",
    "def featuresHRV(signal):\n",
    "    res=[]\n",
    "    ecgResults = ecg(signal,sampling_rate=300, show=False)\n",
    "    rpeaks = ecgResults[2]\n",
    "    nni = tools.nn_intervals(ecgResults[2])\n",
    "    a = td.nni_parameters(nni,rpeaks)\n",
    "    for el in a:\n",
    "        res.append(el)\n",
    "    b = td.nni_differences_parameters(nni,rpeaks)\n",
    "    for el in b:\n",
    "        res.append(el)\n",
    "    c = td.hr_parameters(nni,rpeaks)\n",
    "    for el in c:\n",
    "        res.append(el)\n",
    "    d = td.sdnn(nni,rpeaks)\n",
    "    for el in d:\n",
    "        res.append(el)\n",
    "    e = td.rmssd(nni,rpeaks)\n",
    "    for el in e:\n",
    "        res.append(el)\n",
    "    f = td.sdsd(nni,rpeaks)\n",
    "    for el in f:\n",
    "        res.append(el)  \n",
    "    x = td.nnXX(nni,rpeaks,5)\n",
    "    for el in x:\n",
    "        res.append(el)\n",
    "\n",
    "    y = td.nn50(nni,rpeaks)\n",
    "    for el in y:\n",
    "        res.append(el)\n",
    "\n",
    "    z = td.nn20(nni,rpeaks)\n",
    "    for el in z:\n",
    "        res.append(el)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4947/4947 [02:39<00:00, 31.07it/s]\n"
     ]
    }
   ],
   "source": [
    "features_hrv = []\n",
    "\n",
    "for i,row in tqdm(X_no3.iterrows(), total=X_no3.shape[0],position=0, leave=True): \n",
    "    features_hrv.append(featuresHRV(row))\n",
    "    \n",
    "features_hrv = np.array(features_hrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrv = pd.DataFrame(np.array(features_hrv))\n",
    "df_mo = pd.DataFrame(np.array(moFeatures))\n",
    "df_nici = pd.DataFrame(np.array(niciFeatures))\n",
    "\n",
    "df_hrv.to_csv('df_hrv_train_unscaled.csv',index=False)\n",
    "df_mo.to_csv('df_mo_train_unscaled.csv',index=False)\n",
    "df_nici.to_csv('df_nici_train_unscaled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerHRV = StandardScaler().fit(df_hrv)\n",
    "df_hrv_scaled = pd.DataFrame(scalerHRV.transform(df_hrv))\n",
    "\n",
    "scalerMo = StandardScaler().fit(df_mo)\n",
    "df_mo_scaled = pd.DataFrame(scalerMo.transform(df_mo))\n",
    "\n",
    "scalerNici = StandardScaler().fit(df_nici)\n",
    "df_nici_scaled = pd.DataFrame(scalerNici.transform(df_nici))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrv_scaled.to_csv('df_hrv_train.csv',index=False)\n",
    "df_mo_scaled.to_csv('df_mo_train.csv',index=False)\n",
    "df_nici_scaled.to_csv('df_nici_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = pd.read_csv('X_test.csv')\n",
    "X_t = X_t.drop(['id'],axis=1)\n",
    "X_t = X_t.fillna(0.0)\n",
    "X_t.at[3410,'x17978'] = 0.0\n",
    "X_t = X_t.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "invs = []\n",
    "fract = []\n",
    "for i in range(0, X_t.shape[0]):\n",
    "    var = onlyVar(X_t.iloc[i])\n",
    "    varI = onlyVar(X_t.iloc[i]*(-1))\n",
    "    if (varI < var):\n",
    "        invs.append(-1)\n",
    "        fract.append(var/varI)\n",
    "    else:\n",
    "        invs.append(1)\n",
    "        fract.append(varI/var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr_t = X_t.mul(np.array(invs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,X_corr_t.shape[0]):\n",
    "    signal = X_corr_t.iloc[i]\n",
    "    if (i ==584):\n",
    "        print(i)\n",
    "    else:\n",
    "        newsignal = delMessfehlerMinimum(signal,1.7,50)\n",
    "        newsignal = delMessfehlerMaximum(newsignal,1.7,50)\n",
    "        X_corr_t.iloc[i] = newsignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nici Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3411/3411 [56:28<00:00,  1.01it/s]  \n"
     ]
    }
   ],
   "source": [
    "niciFeatures_t = []\n",
    "\n",
    "for i,row in tqdm(X_corr_t.iterrows(), total=X_corr_t.shape[0],position=0, leave=True):    \n",
    "    # Appply sliding window\n",
    "    var, start, end, templates, pr = shiftWindow(8,row)\n",
    "    \n",
    "    # find P,Q,R etc.\n",
    "    swaped = np.swapaxes(templates,1,0)\n",
    "    signal = []\n",
    "    for i in range(0,180):\n",
    "        signal.append(np.median(swaped[i]))\n",
    "    signal = np.array(signal)\n",
    "    P = findP(signal)\n",
    "    Q = findQ(signal)\n",
    "    R = findR(signal)\n",
    "    S = findS(signal)\n",
    "    T = findT(signal)\n",
    "    Ts = findTstart(signal, T)\n",
    "    Te = findTend(signal, T)\n",
    "    STelbow = findSTelbow(signal,S)\n",
    "    mins = QRTrendChange(signal, Q, R)\n",
    "    var1, var2 =  varClusters(templates,P, R-3)\n",
    "    \n",
    "    a = [var, P, signal[P], Q, signal[Q], signal[R], S, signal[S], \n",
    "        T, signal[T], Ts, signal[Ts], Te, signal[Te],\n",
    "        STelbow, signal[STelbow], mins, var1, var2]\n",
    "    \n",
    "    niciFeatures_t.append(a)\n",
    "    \n",
    "niciFeatures_t = np.array(niciFeatures_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3411/3411 [01:46<00:00, 32.07it/s]\n"
     ]
    }
   ],
   "source": [
    "moFeatures_t = []\n",
    "\n",
    "for i,row in tqdm(X_corr_t.iterrows(), total=X_corr_t.shape[0],position=0, leave=True): \n",
    "    moFeatures_t.append(classfeatures(row))\n",
    "    \n",
    "moFeatures_t = np.array(moFeatures_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRV features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3411/3411 [01:50<00:00, 30.96it/s]\n"
     ]
    }
   ],
   "source": [
    "features_hrv_t = []\n",
    "\n",
    "for i,row in tqdm(X_corr_t.iterrows(), total=X_corr_t.shape[0],position=0, leave=True): \n",
    "    features_hrv_t.append(featuresHRV(row))\n",
    "    \n",
    "features_hrv_t = np.array(features_hrv_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrv_t = pd.DataFrame(np.array(features_hrv_t))\n",
    "df_mo_t = pd.DataFrame(np.array(moFeatures_t))\n",
    "df_nici_t = pd.DataFrame(np.array(niciFeatures_t))\n",
    "\n",
    "df_hrv_t.to_csv('df_hrv_test_unscaled.csv',index=False)\n",
    "df_mo_t.to_csv('df_mo_test_unscaled.csv',index=False)\n",
    "df_nici_t.to_csv('df_nici_test_unscaled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrv_t_scaled = pd.DataFrame(scalerHRV.transform(df_hrv_t))\n",
    "df_mo_t_scaled = pd.DataFrame(scalerMo.transform(df_mo_t))\n",
    "df_nici_t_scaled = pd.DataFrame(scalerNici.transform(df_nici_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hrv_t_scaled.to_csv('df_hrv_test.csv',index=False)\n",
    "df_mo_t_scaled.to_csv('df_mo_test.csv',index=False)\n",
    "df_nici_t_scaled.to_csv('df_nici_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nici + HRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_nici_scaled,df_hrv_scaled],axis=1)\n",
    "df_test = pd.concat([df_nici_t_scaled,df_hrv_t_scaled],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89563507e+01, 9.02038419e+01, 1.08773866e+02, 4.92403167e+01,\n",
       "       1.73871014e+00, 1.34266124e+00, 4.55441388e+01, 1.13933106e+01,\n",
       "       8.97075982e+01, 9.41842654e+00, 1.84834986e+01, 7.18241907e+00,\n",
       "       4.75485996e+00, 2.06613514e-01, 4.35442559e+01, 1.19724557e+01,\n",
       "       2.33405493e+01, 2.40413212e+01, 2.16884142e+01, 1.01027402e+02,\n",
       "       1.21234865e+02, 1.59642753e+02, 4.89577251e+01, 4.61710178e+02,\n",
       "       4.02069981e+01, 2.25405392e+02, 2.79598638e+02, 9.93261103e+00,\n",
       "       2.08422619e+01, 4.58997187e+01, 1.81560976e+02, 3.09294278e+02,\n",
       "       1.66617658e+02, 7.16744991e+02, 4.96354999e+02, 7.78497036e+02,\n",
       "       8.13402762e+02, 1.29409760e+03, 1.25073819e+03])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "selector = SelectKBest(f_classif, k=20).fit(df_train, np.ravel(y_no3))\n",
    "selector.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Poly (~ 76%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pactools.grid_search import GridSearchCVProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 01:42:00.273894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.7768\n",
      "Best parameters: {'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_poly__degree': 3, 'svm_poly__gamma': 'scale'}\n",
      "2020-11-29 01:42:02.141585\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('svm_poly', SVC(kernel='poly', random_state=0, class_weight = \"balanced\"))])\n",
    "#######Polynomial Kernel Function#######\n",
    "param_grid = {'svm_poly__C': [1] ,\n",
    "              'svm_poly__degree': [3],\n",
    "              'svm_poly__gamma': ['scale'],\n",
    "              'svm_poly__coef0':[1]}\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro' )\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svm_poly__C</th>\n",
       "      <th>param_svm_poly__coef0</th>\n",
       "      <th>param_svm_poly__degree</th>\n",
       "      <th>param_svm_poly__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483921</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.035753</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.755061</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.77683</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.483921      0.011736         0.035753        0.000512   \n",
       "\n",
       "  param_svm_poly__C param_svm_poly__coef0 param_svm_poly__degree  \\\n",
       "0                 1                     1                      3   \n",
       "\n",
       "  param_svm_poly__gamma                                             params  \\\n",
       "0                 scale  {'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_...   \n",
       "\n",
       "   split0_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0           0.769697  ...           0.783838           0.771717   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.783838           0.775758           0.775304           0.755061   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.777328          0.77683        0.009851                1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = SVC(kernel='poly',class_weight = \"balanced\")\n",
    "clf_svm.fit(df_train, np.ravel(y_no3))\n",
    "ypred = clf_svm.predict(df_test)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('svmPoly.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM RBF (~ 76%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   4 out of  20 | elapsed:    0.8s remaining:    3.0s\n",
      "[Parallel(n_jobs=22)]: Done   7 out of  20 | elapsed:    0.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=22)]: Done  10 out of  20 | elapsed:    0.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=22)]: Done  13 out of  20 | elapsed:    1.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=22)]: Done  16 out of  20 | elapsed:    1.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=22)]: Done  20 out of  20 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 01:42:05.064915\n",
      "Best F1 score: 0.7778\n",
      "Best parameters: {'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf__gamma': 'scale'}\n",
      "2020-11-29 01:42:05.065070\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)), \n",
    "                     ('svm_rbf', SVC(kernel='rbf', random_state=0, class_weight = \"balanced\"))])\n",
    "#######RBF Kernel Function#######\n",
    "param_grid = {'selector__k': [10,39],\n",
    "              'svm_rbf__C': [1], \n",
    "              'svm_rbf__gamma': ['scale'] }\n",
    "\n",
    "# Run grid search\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro', verbose=10)\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print(datetime.datetime.now()) #computation time\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>param_svm_rbf__C</th>\n",
       "      <th>param_svm_rbf__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401886</td>\n",
       "      <td>0.061911</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'selector__k': 10, 'svm_rbf__C': 1, 'svm_rbf_...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.729293</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.672065</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698982</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.055616</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf_...</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.765657</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.777844</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.401886      0.061911         0.024864        0.004319   \n",
       "1       0.698982      0.068089         0.055616        0.008217   \n",
       "\n",
       "  param_selector__k param_svm_rbf__C param_svm_rbf__gamma  \\\n",
       "0                10                1                scale   \n",
       "1                39                1                scale   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'selector__k': 10, 'svm_rbf__C': 1, 'svm_rbf_...           0.711111   \n",
       "1  {'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf_...           0.767677   \n",
       "\n",
       "   split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0           0.717172  ...           0.745455           0.749495   \n",
       "1           0.779798  ...           0.781818           0.765657   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.729293           0.721212           0.775304           0.672065   \n",
       "1           0.783838           0.787879           0.773279           0.769231   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.736842         0.732360        0.028088                2  \n",
       "1           0.785425         0.777844        0.007724                1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "SelectorSVM = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorSVM.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorSVM.transform(df_test))\n",
    "\n",
    "clf_svm = SVC(kernel='rbf',class_weight = \"balanced\")\n",
    "clf_svm.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_svm.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('svmRBF.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest classifier (~80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 01:42:05.969928\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=22)]: Done  17 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=22)]: Done  28 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=22)]: Done  41 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=22)]: Done  54 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=22)]: Done  69 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=22)]: Done  84 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=22)]: Done 101 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=22)]: Done 118 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=22)]: Done 137 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=22)]: Done 177 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=22)]: Done 198 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=22)]: Done 221 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=22)]: Done 244 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=22)]: Done 269 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=22)]: Done 294 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=22)]: Done 321 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=22)]: Done 348 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=22)]: Done 377 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=22)]: Done 406 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=22)]: Done 437 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=22)]: Done 468 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=22)]: Done 501 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=22)]: Done 534 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=22)]: Done 569 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=22)]: Done 604 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=22)]: Done 641 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=22)]: Done 678 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=22)]: Done 717 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=22)]: Done 756 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=22)]: Done 797 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=22)]: Done 838 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=22)]: Done 881 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=22)]: Done 960 out of 960 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.8136\n",
      "Best parameters: {'RF__class_weight': None, 'RF__max_depth': 20, 'RF__n_estimators': 100, 'selector__k': 30}\n",
      "2020-11-29 01:45:53.520701\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler and RF estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)), \n",
    "                     ('RF', RandomForestClassifier(random_state=0))])\n",
    "#######RF Kernel Function#######\n",
    "param_grid = {'selector__k': [10,20,30,39],\n",
    "              'RF__n_estimators': [100,500,1000], \n",
    "              'RF__max_depth': [5,10,15,20],\n",
    "              'RF__class_weight': [None,'balanced']\n",
    "             }\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro',verbose=10 )\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RF__class_weight</th>\n",
       "      <th>param_RF__max_depth</th>\n",
       "      <th>param_RF__n_estimators</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.409740</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.759596</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757085</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.757220</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513453</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.773737</td>\n",
       "      <td>0.773737</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.787449</td>\n",
       "      <td>0.780068</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583532</td>\n",
       "      <td>0.028281</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.779352</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.779352</td>\n",
       "      <td>0.780674</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.019862</td>\n",
       "      <td>0.044405</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.773737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.757019</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7.984330</td>\n",
       "      <td>0.192597</td>\n",
       "      <td>0.071774</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>0.795547</td>\n",
       "      <td>0.819838</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7.996780</td>\n",
       "      <td>0.180704</td>\n",
       "      <td>0.142144</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765657</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.765657</td>\n",
       "      <td>0.771255</td>\n",
       "      <td>0.722672</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10.745809</td>\n",
       "      <td>0.196730</td>\n",
       "      <td>0.135334</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.799595</td>\n",
       "      <td>0.804929</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>12.500927</td>\n",
       "      <td>0.299007</td>\n",
       "      <td>0.125632</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.814141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.809717</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>14.287694</td>\n",
       "      <td>0.504050</td>\n",
       "      <td>0.109309</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802020</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.795547</td>\n",
       "      <td>0.817814</td>\n",
       "      <td>0.810186</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.409740      0.010586         0.012372        0.001445   \n",
       "1        0.513453      0.022473         0.013154        0.001039   \n",
       "2        0.583532      0.028281         0.012252        0.001665   \n",
       "3        0.723200      0.030459         0.012853        0.001514   \n",
       "4        2.019862      0.044405         0.051508        0.004404   \n",
       "..            ...           ...              ...             ...   \n",
       "91       7.984330      0.192597         0.071774        0.005335   \n",
       "92       7.996780      0.180704         0.142144        0.008189   \n",
       "93      10.745809      0.196730         0.135334        0.010171   \n",
       "94      12.500927      0.299007         0.125632        0.012108   \n",
       "95      14.287694      0.504050         0.109309        0.001460   \n",
       "\n",
       "   param_RF__class_weight param_RF__max_depth param_RF__n_estimators  \\\n",
       "0                    None                   5                    100   \n",
       "1                    None                   5                    100   \n",
       "2                    None                   5                    100   \n",
       "3                    None                   5                    100   \n",
       "4                    None                   5                    500   \n",
       "..                    ...                 ...                    ...   \n",
       "91               balanced                  20                    500   \n",
       "92               balanced                  20                   1000   \n",
       "93               balanced                  20                   1000   \n",
       "94               balanced                  20                   1000   \n",
       "95               balanced                  20                   1000   \n",
       "\n",
       "   param_selector__k                                             params  \\\n",
       "0                 10  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "1                 20  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "2                 30  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "3                 39  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "4                 10  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "..               ...                                                ...   \n",
       "91                39  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "92                10  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "93                20  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "94                30  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "95                39  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "\n",
       "    split0_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0            0.771717  ...           0.755556           0.755556   \n",
       "1            0.781818  ...           0.787879           0.779798   \n",
       "2            0.781818  ...           0.791919           0.781818   \n",
       "3            0.783838  ...           0.783838           0.779798   \n",
       "4            0.773737  ...           0.757576           0.751515   \n",
       "..                ...  ...                ...                ...   \n",
       "91           0.816162  ...           0.818182           0.800000   \n",
       "92           0.783838  ...           0.765657           0.781818   \n",
       "93           0.797980  ...           0.806061           0.806061   \n",
       "94           0.814141  ...           0.818182           0.793939   \n",
       "95           0.818182  ...           0.816162           0.800000   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.759596           0.757576           0.757085   \n",
       "1            0.773737           0.773737           0.775304   \n",
       "2            0.767677           0.781818           0.779352   \n",
       "3            0.771717           0.777778           0.773279   \n",
       "4            0.755556           0.755556           0.761134   \n",
       "..                ...                ...                ...   \n",
       "91           0.800000           0.822222           0.811741   \n",
       "92           0.761616           0.765657           0.771255   \n",
       "93           0.800000           0.797980           0.803644   \n",
       "94           0.793939           0.806061           0.807692   \n",
       "95           0.802020           0.812121           0.805668   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.710526           0.769231         0.757220        0.017790   \n",
       "1            0.775304           0.787449         0.780068        0.007774   \n",
       "2            0.775304           0.779352         0.780674        0.008670   \n",
       "3            0.775304           0.785425         0.780269        0.008171   \n",
       "4            0.712551           0.769231         0.757019        0.017288   \n",
       "..                ...                ...              ...             ...   \n",
       "91           0.795547           0.819838         0.812410        0.010986   \n",
       "92           0.722672           0.761134         0.765304        0.017889   \n",
       "93           0.793522           0.799595         0.804929        0.016487   \n",
       "94           0.793522           0.809717         0.806144        0.011891   \n",
       "95           0.795547           0.817814         0.810186        0.009108   \n",
       "\n",
       "    rank_test_score  \n",
       "0                84  \n",
       "1                63  \n",
       "2                61  \n",
       "3                62  \n",
       "4                86  \n",
       "..              ...  \n",
       "91                3  \n",
       "92               76  \n",
       "93               28  \n",
       "94               24  \n",
       "95               13  \n",
       "\n",
       "[96 rows x 22 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "class_weight = grid.best_params_['RF__class_weight']\n",
    "n_estimators = grid.best_params_['RF__n_estimators']\n",
    "max_depth = grid.best_params_['RF__max_depth']\n",
    "\n",
    "\n",
    "SelectorRF = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorRF.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorRF.transform(df_test))\n",
    "\n",
    "clf_rf = RandomForestClassifier(class_weight=class_weight, n_estimators=n_estimators, max_depth=max_depth)\n",
    "clf_rf.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_rf.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('randomForest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradientboosting (~80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 01:45:54.766523\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=22)]: Done  17 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=22)]: Done  28 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=22)]: Done  41 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=22)]: Done  54 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=22)]: Done  69 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=22)]: Done  84 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=22)]: Done 101 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=22)]: Done 118 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=22)]: Done 137 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=22)]: Done 177 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=22)]: Done 198 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=22)]: Done 221 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=22)]: Done 244 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=22)]: Done 269 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=22)]: Done 294 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=22)]: Done 321 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=22)]: Done 348 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=22)]: Done 377 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=22)]: Done 406 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=22)]: Done 437 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=22)]: Done 468 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=22)]: Done 501 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=22)]: Done 534 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=22)]: Done 569 tasks      | elapsed: 58.0min\n",
      "[Parallel(n_jobs=22)]: Done 604 tasks      | elapsed: 68.5min\n",
      "[Parallel(n_jobs=22)]: Done 641 tasks      | elapsed: 75.8min\n",
      "[Parallel(n_jobs=22)]: Done 678 tasks      | elapsed: 77.7min\n",
      "[Parallel(n_jobs=22)]: Done 717 tasks      | elapsed: 80.6min\n",
      "[Parallel(n_jobs=22)]: Done 756 tasks      | elapsed: 83.7min\n",
      "[Parallel(n_jobs=22)]: Done 797 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=22)]: Done 838 tasks      | elapsed: 87.9min\n",
      "[Parallel(n_jobs=22)]: Done 881 tasks      | elapsed: 91.1min\n",
      "[Parallel(n_jobs=22)]: Done 924 tasks      | elapsed: 96.4min\n",
      "[Parallel(n_jobs=22)]: Done 969 tasks      | elapsed: 101.0min\n",
      "[Parallel(n_jobs=22)]: Done 1014 tasks      | elapsed: 105.0min\n",
      "[Parallel(n_jobs=22)]: Done 1061 tasks      | elapsed: 113.3min\n",
      "[Parallel(n_jobs=22)]: Done 1108 tasks      | elapsed: 122.4min\n",
      "[Parallel(n_jobs=22)]: Done 1157 tasks      | elapsed: 127.3min\n",
      "[Parallel(n_jobs=22)]: Done 1206 tasks      | elapsed: 134.9min\n",
      "[Parallel(n_jobs=22)]: Done 1280 out of 1280 | elapsed: 160.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.8217\n",
      "Best parameters: {'GBoost__learning_rate': 0.1, 'GBoost__max_depth': 5, 'GBoost__n_estimators': 1000, 'selector__k': 39}\n",
      "2020-11-29 04:28:31.426855\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler and Adaboost estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)),\n",
    "                     ('GBoost', GradientBoostingClassifier(random_state=0))])\n",
    "#######Adaboost Kernel Function#######\n",
    "param_grid = {'selector__k': [10,20,30,39],\n",
    "              'GBoost__n_estimators': [100,500,750,1000], \n",
    "              'GBoost__learning_rate': [0.1,1],\n",
    "              'GBoost__max_depth': [5,10,15,20]\n",
    "             }\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro',verbose=10)\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_GBoost__learning_rate</th>\n",
       "      <th>param_GBoost__max_depth</th>\n",
       "      <th>param_GBoost__n_estimators</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.282498</td>\n",
       "      <td>0.128145</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.738866</td>\n",
       "      <td>0.751012</td>\n",
       "      <td>0.765507</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.382379</td>\n",
       "      <td>0.222854</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.827935</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.808568</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.783654</td>\n",
       "      <td>0.334157</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.802020</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.846471</td>\n",
       "      <td>0.217535</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.787449</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.815236</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.314631</td>\n",
       "      <td>0.718843</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.759596</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.726721</td>\n",
       "      <td>0.753174</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>490.722412</td>\n",
       "      <td>6.758321</td>\n",
       "      <td>0.186940</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.719192</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.696356</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.704055</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>231.933314</td>\n",
       "      <td>6.190729</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682828</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.655870</td>\n",
       "      <td>0.714575</td>\n",
       "      <td>0.690719</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>366.368977</td>\n",
       "      <td>8.374371</td>\n",
       "      <td>0.225891</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.713131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664646</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.678788</td>\n",
       "      <td>0.640404</td>\n",
       "      <td>0.663968</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.751012</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>499.796656</td>\n",
       "      <td>11.581218</td>\n",
       "      <td>0.230856</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658586</td>\n",
       "      <td>0.589899</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.665992</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.655351</td>\n",
       "      <td>0.029198</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>579.772565</td>\n",
       "      <td>17.696533</td>\n",
       "      <td>0.209042</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.668687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.698990</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.661943</td>\n",
       "      <td>0.674089</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.686671</td>\n",
       "      <td>0.018057</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         4.282498      0.128145         0.005460        0.000670   \n",
       "1         8.382379      0.222854         0.005711        0.000383   \n",
       "2        11.783654      0.334157         0.005652        0.000349   \n",
       "3        16.846471      0.217535         0.005634        0.000410   \n",
       "4        21.314631      0.718843         0.014622        0.001605   \n",
       "..             ...           ...              ...             ...   \n",
       "123     490.722412      6.758321         0.186940        0.005036   \n",
       "124     231.933314      6.190729         0.220644        0.009145   \n",
       "125     366.368977      8.374371         0.225891        0.014063   \n",
       "126     499.796656     11.581218         0.230856        0.012695   \n",
       "127     579.772565     17.696533         0.209042        0.005920   \n",
       "\n",
       "    param_GBoost__learning_rate param_GBoost__max_depth  \\\n",
       "0                           0.1                       5   \n",
       "1                           0.1                       5   \n",
       "2                           0.1                       5   \n",
       "3                           0.1                       5   \n",
       "4                           0.1                       5   \n",
       "..                          ...                     ...   \n",
       "123                           1                      20   \n",
       "124                           1                      20   \n",
       "125                           1                      20   \n",
       "126                           1                      20   \n",
       "127                           1                      20   \n",
       "\n",
       "    param_GBoost__n_estimators param_selector__k  \\\n",
       "0                          100                10   \n",
       "1                          100                20   \n",
       "2                          100                30   \n",
       "3                          100                39   \n",
       "4                          500                10   \n",
       "..                         ...               ...   \n",
       "123                        750                39   \n",
       "124                       1000                10   \n",
       "125                       1000                20   \n",
       "126                       1000                30   \n",
       "127                       1000                39   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.757576   \n",
       "1    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.806061   \n",
       "2    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.824242   \n",
       "3    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.824242   \n",
       "4    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.761616   \n",
       "..                                                 ...                ...   \n",
       "123  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.684848   \n",
       "124  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.707071   \n",
       "125  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.713131   \n",
       "126  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.684848   \n",
       "127  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.668687   \n",
       "\n",
       "     ...  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0    ...           0.769697           0.777778           0.761616   \n",
       "1    ...           0.806061           0.806061           0.804040   \n",
       "2    ...           0.806061           0.810101           0.812121   \n",
       "3    ...           0.830303           0.808081           0.810101   \n",
       "4    ...           0.761616           0.767677           0.759596   \n",
       "..   ...                ...                ...                ...   \n",
       "123  ...           0.725253           0.719192           0.733333   \n",
       "124  ...           0.682828           0.709091           0.676768   \n",
       "125  ...           0.664646           0.725253           0.678788   \n",
       "126  ...           0.658586           0.589899           0.624242   \n",
       "127  ...           0.715152           0.698990           0.717172   \n",
       "\n",
       "     split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0             0.767677           0.769231           0.738866   \n",
       "1             0.804040           0.789474           0.827935   \n",
       "2             0.802020           0.783401           0.842105   \n",
       "3             0.818182           0.787449           0.825911   \n",
       "4             0.739394           0.775304           0.710526   \n",
       "..                 ...                ...                ...   \n",
       "123           0.707071           0.684211           0.696356   \n",
       "124           0.656566           0.690283           0.655870   \n",
       "125           0.640404           0.663968           0.730769   \n",
       "126           0.654545           0.684211           0.665992   \n",
       "127           0.692929           0.661943           0.674089   \n",
       "\n",
       "     split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.751012         0.765507        0.013783               82  \n",
       "1             0.793522         0.808568        0.013458               23  \n",
       "2             0.803644         0.813218        0.016999               11  \n",
       "3             0.805668         0.815236        0.015308                7  \n",
       "4             0.726721         0.753174        0.021429              100  \n",
       "..                 ...              ...             ...              ...  \n",
       "123           0.692308         0.704055        0.016391              123  \n",
       "124           0.714575         0.690719        0.022066              125  \n",
       "125           0.751012         0.699423        0.034133              124  \n",
       "126           0.635628         0.655351        0.029198              128  \n",
       "127           0.684211         0.686671        0.018057              126  \n",
       "\n",
       "[128 rows x 22 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "n_estimators = grid.best_params_['GBoost__n_estimators']\n",
    "learning_rate = grid.best_params_['GBoost__learning_rate']\n",
    "max_depth = grid.best_params_['GBoost__max_depth']\n",
    "\n",
    "\n",
    "SelectorRF = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorRF.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorRF.transform(df_test))\n",
    "\n",
    "clf_gb = GradientBoostingClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth)\n",
    "clf_gb.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_gb.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('gradientBoost.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nici + Mo + HRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_nici_scaled,df_mo_scaled,df_hrv_scaled],axis=1)\n",
    "df_test = pd.concat([df_nici_t_scaled,df_mo_t_scaled,df_hrv_t_scaled],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89563507e+01, 9.02038419e+01, 1.08773866e+02, 4.92403167e+01,\n",
       "       1.73871014e+00, 1.34266124e+00, 4.55441388e+01, 1.13933106e+01,\n",
       "       8.97075982e+01, 9.41842654e+00, 1.84834986e+01, 7.18241907e+00,\n",
       "       4.75485996e+00, 2.06613514e-01, 4.35442559e+01, 1.19724557e+01,\n",
       "       2.33405493e+01, 2.40413212e+01, 2.16884142e+01, 3.56090851e+02,\n",
       "       4.62278699e+00, 4.88670709e+02, 4.08891977e+02, 3.45625889e+02,\n",
       "       1.04464223e+02, 3.36078249e+02, 3.70776319e+02, 9.57304301e+00,\n",
       "       1.13998231e+00, 7.99999348e+00, 7.59227611e+01, 3.33816936e+00,\n",
       "       4.08075374e+01, 1.06746963e+01, 3.87278351e+00, 4.15995366e+01,\n",
       "       1.01027402e+02, 1.21234865e+02, 1.59642753e+02, 4.89577251e+01,\n",
       "       4.61710178e+02, 4.02069981e+01, 2.25405392e+02, 2.79598638e+02,\n",
       "       9.93261103e+00, 2.08422619e+01, 4.58997187e+01, 1.81560976e+02,\n",
       "       3.09294278e+02, 1.66617658e+02, 7.16744991e+02, 4.96354999e+02,\n",
       "       7.78497036e+02, 8.13402762e+02, 1.29409760e+03, 1.25073819e+03])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "selector = SelectKBest(f_classif, k=20).fit(df_train, np.ravel(y_no3))\n",
    "selector.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Poly (~ 76%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pactools.grid_search import GridSearchCVProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 04:30:58.105852\n",
      "Best F1 score: 0.7851\n",
      "Best parameters: {'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_poly__degree': 3, 'svm_poly__gamma': 'scale'}\n",
      "2020-11-29 04:31:00.185370\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('svm_poly', SVC(kernel='poly', random_state=0, class_weight = \"balanced\"))])\n",
    "#######Polynomial Kernel Function#######\n",
    "param_grid = {'svm_poly__C': [1] ,\n",
    "              'svm_poly__degree': [3],\n",
    "              'svm_poly__gamma': ['scale'],\n",
    "              'svm_poly__coef0':[1]}\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro' )\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svm_poly__C</th>\n",
       "      <th>param_svm_poly__coef0</th>\n",
       "      <th>param_svm_poly__degree</th>\n",
       "      <th>param_svm_poly__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.01327</td>\n",
       "      <td>0.047142</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.773737</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.767206</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.785119</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.568075       0.01327         0.047142        0.000451   \n",
       "\n",
       "  param_svm_poly__C param_svm_poly__coef0 param_svm_poly__degree  \\\n",
       "0                 1                     1                      3   \n",
       "\n",
       "  param_svm_poly__gamma                                             params  \\\n",
       "0                 scale  {'svm_poly__C': 1, 'svm_poly__coef0': 1, 'svm_...   \n",
       "\n",
       "   split0_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0                0.8  ...                0.8           0.779798   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.773737           0.783838           0.789474           0.767206   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.783401         0.785119        0.010011                1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = SVC(kernel='poly',class_weight = \"balanced\")\n",
    "clf_svm.fit(df_train, np.ravel(y_no3))\n",
    "ypred = clf_svm.predict(df_test)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('svmPolyAll.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM RBF (~ 76%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   4 out of  20 | elapsed:    0.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=22)]: Done   7 out of  20 | elapsed:    0.8s remaining:    1.4s\n",
      "[Parallel(n_jobs=22)]: Done  10 out of  20 | elapsed:    0.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=22)]: Done  13 out of  20 | elapsed:    1.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=22)]: Done  16 out of  20 | elapsed:    1.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=22)]: Done  20 out of  20 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 04:31:03.410322\n",
      "Best F1 score: 0.7839\n",
      "Best parameters: {'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf__gamma': 'scale'}\n",
      "2020-11-29 04:31:03.410487\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)), \n",
    "                     ('svm_rbf', SVC(kernel='rbf', random_state=0, class_weight = \"balanced\"))])\n",
    "#######RBF Kernel Function#######\n",
    "param_grid = {'selector__k': [10,39],\n",
    "              'svm_rbf__C': [1], \n",
    "              'svm_rbf__gamma': ['scale'] }\n",
    "\n",
    "# Run grid search\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro', verbose=10)\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print(datetime.datetime.now()) #computation time\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>param_svm_rbf__C</th>\n",
       "      <th>param_svm_rbf__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396293</td>\n",
       "      <td>0.035809</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'selector__k': 10, 'svm_rbf__C': 1, 'svm_rbf_...</td>\n",
       "      <td>0.719192</td>\n",
       "      <td>0.713131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.748988</td>\n",
       "      <td>0.674089</td>\n",
       "      <td>0.728745</td>\n",
       "      <td>0.715788</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622175</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.048848</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf_...</td>\n",
       "      <td>0.814141</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795960</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>0.783906</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.396293      0.035809         0.022376        0.000914   \n",
       "1       0.622175      0.052348         0.048848        0.007523   \n",
       "\n",
       "  param_selector__k param_svm_rbf__C param_svm_rbf__gamma  \\\n",
       "0                10                1                scale   \n",
       "1                39                1                scale   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'selector__k': 10, 'svm_rbf__C': 1, 'svm_rbf_...           0.719192   \n",
       "1  {'selector__k': 39, 'svm_rbf__C': 1, 'svm_rbf_...           0.814141   \n",
       "\n",
       "   split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0           0.713131  ...           0.743434           0.733333   \n",
       "1           0.771717  ...           0.795960           0.769697   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.676768           0.656566           0.748988           0.674089   \n",
       "1           0.779798           0.779798           0.785425           0.769231   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.728745         0.715788        0.033792                2  \n",
       "1           0.781377         0.783906        0.013160                1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "SelectorSVM = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorSVM.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorSVM.transform(df_test))\n",
    "\n",
    "clf_svm = SVC(kernel='rbf',class_weight = \"balanced\")\n",
    "clf_svm.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_svm.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('svmRBFAll.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest classifier (~80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 04:31:04.304002\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=22)]: Done  17 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=22)]: Done  28 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=22)]: Done  41 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=22)]: Done  54 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=22)]: Done  69 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=22)]: Done  84 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=22)]: Done 101 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=22)]: Done 118 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=22)]: Done 137 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=22)]: Done 177 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=22)]: Done 198 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=22)]: Done 221 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=22)]: Done 244 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=22)]: Done 269 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=22)]: Done 294 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=22)]: Done 321 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=22)]: Done 348 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=22)]: Done 377 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=22)]: Done 406 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=22)]: Done 437 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=22)]: Done 468 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=22)]: Done 501 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=22)]: Done 534 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=22)]: Done 569 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=22)]: Done 604 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=22)]: Done 641 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=22)]: Done 678 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=22)]: Done 717 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=22)]: Done 756 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=22)]: Done 797 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=22)]: Done 838 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=22)]: Done 881 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=22)]: Done 960 out of 960 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.8219\n",
      "Best parameters: {'RF__class_weight': None, 'RF__max_depth': 20, 'RF__n_estimators': 1000, 'selector__k': 39}\n",
      "2020-11-29 04:35:04.051036\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler and RF estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)), \n",
    "                     ('RF', RandomForestClassifier(random_state=0))])\n",
    "#######RF Kernel Function#######\n",
    "param_grid = {'selector__k': [10,20,30,39],\n",
    "              'RF__n_estimators': [100,500,1000], \n",
    "              'RF__max_depth': [5,10,15,20],\n",
    "              'RF__class_weight': [None,'balanced']\n",
    "             }\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro',verbose=10 )\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RF__class_weight</th>\n",
       "      <th>param_RF__max_depth</th>\n",
       "      <th>param_RF__n_estimators</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.383710</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.723232</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.767206</td>\n",
       "      <td>0.714575</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.753589</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543163</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>0.751012</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.776426</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587240</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789899</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.757085</td>\n",
       "      <td>0.791498</td>\n",
       "      <td>0.783702</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705447</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789899</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.785859</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.779352</td>\n",
       "      <td>0.765182</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.783906</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.860906</td>\n",
       "      <td>0.094310</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': None, 'RF__max_depth': 5,...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714575</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.753184</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7.740774</td>\n",
       "      <td>0.178633</td>\n",
       "      <td>0.071495</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.809717</td>\n",
       "      <td>0.814026</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7.527106</td>\n",
       "      <td>0.221206</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.779798</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.718623</td>\n",
       "      <td>0.771255</td>\n",
       "      <td>0.758235</td>\n",
       "      <td>0.023237</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>11.096777</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.789899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795960</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.785859</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.767206</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.789566</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>13.065811</td>\n",
       "      <td>0.427069</td>\n",
       "      <td>0.130898</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.802020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.802020</td>\n",
       "      <td>0.802020</td>\n",
       "      <td>0.819838</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>0.808369</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13.951905</td>\n",
       "      <td>0.518651</td>\n",
       "      <td>0.107299</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>39</td>\n",
       "      <td>{'RF__class_weight': 'balanced', 'RF__max_dept...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820202</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.831984</td>\n",
       "      <td>0.795547</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.814027</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.383710      0.015944         0.011985        0.001302   \n",
       "1        0.543163      0.010269         0.013047        0.000987   \n",
       "2        0.587240      0.034651         0.011307        0.001122   \n",
       "3        0.705447      0.007410         0.012996        0.000944   \n",
       "4        1.860906      0.094310         0.050125        0.003719   \n",
       "..            ...           ...              ...             ...   \n",
       "91       7.740774      0.178633         0.071495        0.002320   \n",
       "92       7.527106      0.221206         0.141631        0.016207   \n",
       "93      11.096777      0.176352         0.136789        0.010244   \n",
       "94      13.065811      0.427069         0.130898        0.012667   \n",
       "95      13.951905      0.518651         0.107299        0.003295   \n",
       "\n",
       "   param_RF__class_weight param_RF__max_depth param_RF__n_estimators  \\\n",
       "0                    None                   5                    100   \n",
       "1                    None                   5                    100   \n",
       "2                    None                   5                    100   \n",
       "3                    None                   5                    100   \n",
       "4                    None                   5                    500   \n",
       "..                    ...                 ...                    ...   \n",
       "91               balanced                  20                    500   \n",
       "92               balanced                  20                   1000   \n",
       "93               balanced                  20                   1000   \n",
       "94               balanced                  20                   1000   \n",
       "95               balanced                  20                   1000   \n",
       "\n",
       "   param_selector__k                                             params  \\\n",
       "0                 10  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "1                 20  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "2                 30  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "3                 39  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "4                 10  {'RF__class_weight': None, 'RF__max_depth': 5,...   \n",
       "..               ...                                                ...   \n",
       "91                39  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "92                10  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "93                20  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "94                30  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "95                39  {'RF__class_weight': 'balanced', 'RF__max_dept...   \n",
       "\n",
       "    split0_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0            0.769697  ...           0.777778           0.767677   \n",
       "1            0.787879  ...           0.779798           0.767677   \n",
       "2            0.791919  ...           0.789899           0.791919   \n",
       "3            0.783838  ...           0.789899           0.787879   \n",
       "4            0.769697  ...           0.777778           0.763636   \n",
       "..                ...  ...                ...                ...   \n",
       "91           0.826263  ...           0.816162           0.810101   \n",
       "92           0.769697  ...           0.769697           0.779798   \n",
       "93           0.789899  ...           0.795960           0.791919   \n",
       "94           0.802020  ...           0.808081           0.808081   \n",
       "95           0.826263  ...           0.820202           0.804040   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.723232           0.717172           0.767206   \n",
       "1            0.781818           0.787879           0.781377   \n",
       "2            0.777778           0.787879           0.777328   \n",
       "3            0.785859           0.793939           0.779352   \n",
       "4            0.725253           0.717172           0.769231   \n",
       "..                ...                ...                ...   \n",
       "91           0.800000           0.816162           0.825911   \n",
       "92           0.737374           0.721212           0.773279   \n",
       "93           0.791919           0.785859           0.801619   \n",
       "94           0.802020           0.802020           0.819838   \n",
       "95           0.808081           0.810101           0.831984   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.714575           0.783401         0.753589        0.025380   \n",
       "1            0.751012           0.775304         0.776426        0.012049   \n",
       "2            0.757085           0.791498         0.783702        0.013643   \n",
       "3            0.765182           0.789474         0.783906        0.009279   \n",
       "4            0.714575           0.777328         0.753184        0.023875   \n",
       "..                ...                ...              ...             ...   \n",
       "91           0.793522           0.809717         0.814026        0.014608   \n",
       "92           0.718623           0.771255         0.758235        0.023237   \n",
       "93           0.767206           0.783401         0.789566        0.012035   \n",
       "94           0.793522           0.811741         0.808369        0.012220   \n",
       "95           0.795547           0.805668         0.814027        0.014232   \n",
       "\n",
       "    rank_test_score  \n",
       "0                84  \n",
       "1                63  \n",
       "2                60  \n",
       "3                59  \n",
       "4                87  \n",
       "..              ...  \n",
       "91               11  \n",
       "92               77  \n",
       "93               50  \n",
       "94               26  \n",
       "95               10  \n",
       "\n",
       "[96 rows x 22 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "class_weight = grid.best_params_['RF__class_weight']\n",
    "n_estimators = grid.best_params_['RF__n_estimators']\n",
    "max_depth = grid.best_params_['RF__max_depth']\n",
    "\n",
    "\n",
    "SelectorRF = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorRF.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorRF.transform(df_test))\n",
    "\n",
    "clf_rf = RandomForestClassifier(class_weight=class_weight, n_estimators=n_estimators, max_depth=max_depth)\n",
    "clf_rf.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_rf.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('randomForestAll.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradientboosting (~80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-29 04:35:18.936074\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=22)]: Using backend LokyBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=22)]: Done  17 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=22)]: Done  28 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=22)]: Done  41 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=22)]: Done  54 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=22)]: Done  69 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=22)]: Done  84 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=22)]: Done 101 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=22)]: Done 118 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=22)]: Done 137 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=22)]: Done 177 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=22)]: Done 198 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=22)]: Done 221 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=22)]: Done 244 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=22)]: Done 269 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=22)]: Done 294 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=22)]: Done 321 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=22)]: Done 348 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=22)]: Done 377 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=22)]: Done 406 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=22)]: Done 437 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=22)]: Done 468 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=22)]: Done 501 tasks      | elapsed: 47.0min\n",
      "[Parallel(n_jobs=22)]: Done 534 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=22)]: Done 569 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=22)]: Done 604 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=22)]: Done 641 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=22)]: Done 678 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=22)]: Done 717 tasks      | elapsed: 81.0min\n",
      "[Parallel(n_jobs=22)]: Done 756 tasks      | elapsed: 84.2min\n",
      "[Parallel(n_jobs=22)]: Done 797 tasks      | elapsed: 86.6min\n",
      "[Parallel(n_jobs=22)]: Done 838 tasks      | elapsed: 88.2min\n",
      "[Parallel(n_jobs=22)]: Done 881 tasks      | elapsed: 91.4min\n",
      "[Parallel(n_jobs=22)]: Done 924 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=22)]: Done 969 tasks      | elapsed: 101.3min\n",
      "[Parallel(n_jobs=22)]: Done 1014 tasks      | elapsed: 105.0min\n",
      "[Parallel(n_jobs=22)]: Done 1061 tasks      | elapsed: 113.5min\n",
      "[Parallel(n_jobs=22)]: Done 1108 tasks      | elapsed: 122.7min\n",
      "[Parallel(n_jobs=22)]: Done 1157 tasks      | elapsed: 127.3min\n",
      "[Parallel(n_jobs=22)]: Done 1206 tasks      | elapsed: 135.3min\n",
      "[Parallel(n_jobs=22)]: Done 1280 out of 1280 | elapsed: 160.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.8237\n",
      "Best parameters: {'GBoost__learning_rate': 0.1, 'GBoost__max_depth': 5, 'GBoost__n_estimators': 500, 'selector__k': 39}\n",
      "2020-11-29 07:16:44.448096\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler and Adaboost estimator\n",
    "pipe = Pipeline([('selector', SelectKBest(f_classif)),\n",
    "                     ('GBoost', GradientBoostingClassifier(random_state=0))])\n",
    "#######Adaboost Kernel Function#######\n",
    "param_grid = {'selector__k': [10,20,30,39],\n",
    "              'GBoost__n_estimators': [100,500,750,1000], \n",
    "              'GBoost__learning_rate': [0.1,1],\n",
    "              'GBoost__max_depth': [5,10,15,20]\n",
    "             }\n",
    "\n",
    "# Run grid search\n",
    "print(datetime.datetime.now()) #computation time\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=22, scoring = 'f1_micro',verbose=10)\n",
    "grid = grid.fit(df_train, np.ravel(y_no3))\n",
    "\n",
    "print('Best F1 score: {:.4f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_GBoost__learning_rate</th>\n",
       "      <th>param_GBoost__max_depth</th>\n",
       "      <th>param_GBoost__n_estimators</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.795386</td>\n",
       "      <td>0.218057</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.789899</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.700405</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.751363</td>\n",
       "      <td>0.031864</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.926508</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.819838</td>\n",
       "      <td>0.791498</td>\n",
       "      <td>0.779352</td>\n",
       "      <td>0.794018</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.370232</td>\n",
       "      <td>0.370115</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.820202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.816654</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.945668</td>\n",
       "      <td>0.482658</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.832323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.809717</td>\n",
       "      <td>0.821904</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.099640</td>\n",
       "      <td>0.610649</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 0.1, 'GBoost__max_de...</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.694949</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.682186</td>\n",
       "      <td>0.757085</td>\n",
       "      <td>0.740446</td>\n",
       "      <td>0.031955</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>478.594901</td>\n",
       "      <td>6.560956</td>\n",
       "      <td>0.179682</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713131</td>\n",
       "      <td>0.713131</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.700405</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.715782</td>\n",
       "      <td>0.022538</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>225.529424</td>\n",
       "      <td>9.457005</td>\n",
       "      <td>0.222768</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.678788</td>\n",
       "      <td>0.610101</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.706478</td>\n",
       "      <td>0.659919</td>\n",
       "      <td>0.698381</td>\n",
       "      <td>0.681023</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>379.976103</td>\n",
       "      <td>8.041201</td>\n",
       "      <td>0.221689</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.723232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731313</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.735354</td>\n",
       "      <td>0.672065</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.678138</td>\n",
       "      <td>0.687476</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>511.460917</td>\n",
       "      <td>5.367432</td>\n",
       "      <td>0.222046</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.741414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612121</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.670707</td>\n",
       "      <td>0.735354</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.696356</td>\n",
       "      <td>0.686235</td>\n",
       "      <td>0.687882</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>565.480247</td>\n",
       "      <td>17.091917</td>\n",
       "      <td>0.200392</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>39</td>\n",
       "      <td>{'GBoost__learning_rate': 1, 'GBoost__max_dept...</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.663968</td>\n",
       "      <td>0.668016</td>\n",
       "      <td>0.708502</td>\n",
       "      <td>0.691119</td>\n",
       "      <td>0.022047</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         3.795386      0.218057         0.005568        0.000120   \n",
       "1         8.926508      0.128100         0.005766        0.000086   \n",
       "2        12.370232      0.370115         0.005719        0.000356   \n",
       "3        15.945668      0.482658         0.005877        0.000074   \n",
       "4        19.099640      0.610649         0.015652        0.000176   \n",
       "..             ...           ...              ...             ...   \n",
       "123     478.594901      6.560956         0.179682        0.008190   \n",
       "124     225.529424      9.457005         0.222768        0.011161   \n",
       "125     379.976103      8.041201         0.221689        0.012406   \n",
       "126     511.460917      5.367432         0.222046        0.011695   \n",
       "127     565.480247     17.091917         0.200392        0.004887   \n",
       "\n",
       "    param_GBoost__learning_rate param_GBoost__max_depth  \\\n",
       "0                           0.1                       5   \n",
       "1                           0.1                       5   \n",
       "2                           0.1                       5   \n",
       "3                           0.1                       5   \n",
       "4                           0.1                       5   \n",
       "..                          ...                     ...   \n",
       "123                           1                      20   \n",
       "124                           1                      20   \n",
       "125                           1                      20   \n",
       "126                           1                      20   \n",
       "127                           1                      20   \n",
       "\n",
       "    param_GBoost__n_estimators param_selector__k  \\\n",
       "0                          100                10   \n",
       "1                          100                20   \n",
       "2                          100                30   \n",
       "3                          100                39   \n",
       "4                          500                10   \n",
       "..                         ...               ...   \n",
       "123                        750                39   \n",
       "124                       1000                10   \n",
       "125                       1000                20   \n",
       "126                       1000                30   \n",
       "127                       1000                39   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.755556   \n",
       "1    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.783838   \n",
       "2    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.820202   \n",
       "3    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.832323   \n",
       "4    {'GBoost__learning_rate': 0.1, 'GBoost__max_de...           0.737374   \n",
       "..                                                 ...                ...   \n",
       "123  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.743434   \n",
       "124  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.705051   \n",
       "125  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.723232   \n",
       "126  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.741414   \n",
       "127  {'GBoost__learning_rate': 1, 'GBoost__max_dept...           0.705051   \n",
       "\n",
       "     ...  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0    ...           0.763636           0.789899           0.709091   \n",
       "1    ...           0.804040           0.793939           0.771717   \n",
       "2    ...           0.816162           0.816162           0.816162   \n",
       "3    ...           0.826263           0.838384           0.806061   \n",
       "4    ...           0.745455           0.781818           0.711111   \n",
       "..   ...                ...                ...                ...   \n",
       "123  ...           0.713131           0.713131           0.709091   \n",
       "124  ...           0.715152           0.678788           0.610101   \n",
       "125  ...           0.731313           0.703030           0.688889   \n",
       "126  ...           0.612121           0.696970           0.670707   \n",
       "127  ...           0.692929           0.696970           0.688889   \n",
       "\n",
       "     split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0             0.709091           0.783401           0.700405   \n",
       "1             0.787879           0.819838           0.791498   \n",
       "2             0.808081           0.805668           0.815789   \n",
       "3             0.810101           0.803644           0.813765   \n",
       "4             0.694949           0.769231           0.682186   \n",
       "..                 ...                ...                ...   \n",
       "123           0.721212           0.690283           0.700405   \n",
       "124           0.692929           0.706478           0.659919   \n",
       "125           0.735354           0.672065           0.653846   \n",
       "126           0.735354           0.631579           0.696356   \n",
       "127           0.707071           0.663968           0.668016   \n",
       "\n",
       "     split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.761134         0.751363        0.031864               87  \n",
       "1             0.779352         0.794018        0.015331               49  \n",
       "2             0.815789         0.816654        0.011000               10  \n",
       "3             0.809717         0.821904        0.017958                4  \n",
       "4             0.757085         0.740446        0.031955              106  \n",
       "..                 ...              ...             ...              ...  \n",
       "123           0.730769         0.715782        0.022538              117  \n",
       "124           0.698381         0.681023        0.029163              128  \n",
       "125           0.678138         0.687476        0.035036              127  \n",
       "126           0.686235         0.687882        0.040103              126  \n",
       "127           0.708502         0.691119        0.022047              125  \n",
       "\n",
       "[128 rows x 22 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid.best_params_['selector__k']\n",
    "n_estimators = grid.best_params_['GBoost__n_estimators']\n",
    "learning_rate = grid.best_params_['GBoost__learning_rate']\n",
    "max_depth = grid.best_params_['GBoost__max_depth']\n",
    "\n",
    "\n",
    "SelectorRF = SelectKBest(f_classif, k=k)\n",
    "df_train_kbest = pd.DataFrame(SelectorRF.fit_transform(df_train, y_no3))\n",
    "df_test_kbest = pd.DataFrame(SelectorRF.transform(df_test))\n",
    "\n",
    "clf_gb = GradientBoostingClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth)\n",
    "clf_gb.fit(df_train_kbest, np.ravel(y_no3))\n",
    "ypred = clf_gb.predict(df_test_kbest)\n",
    "\n",
    "solution = pd.read_csv('sample.csv')\n",
    "solution['y'] = ypred\n",
    "solution.to_csv('gradientBoostAll.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nicilist1 = [2,60,73,122,199,205,363,391,396,440,766,770,783,852,1008,1020,1142,1200,1314,1498,1527,1584,1898,2113,2765,2857,2882,3068,3098,3100,3318]\n",
    "nicilist2 = [15,44,160,189,203,219,239,256,273,364,385,445,476,505,585,657,732,841,873,877,880,933,977,1034,1079,1501,1596,1612,1658,1751,1819,1857,2007,2014,2058,2067,2070,2110,2140,2234,2253,2373,2387,2478,2507,2513,2627,2657,2696,2806,2820,2953,3016,3022,3039,3174,3304,3317]\n",
    "nicilist3 = [636,809,1034,1417,1421,1473,1672,1675,2251,2301,2728,2844,3207,3308]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClass3files(ypred, filename):\n",
    "    # Nicilist1\n",
    "    ypred = ypred\n",
    "    for i in range(0,np.shape(ypred)[0]):\n",
    "        if i in nicilist1:\n",
    "            ypred[i] = 3\n",
    "    \n",
    "    solution = pd.read_csv('sample.csv')\n",
    "    solution['y'] = ypred\n",
    "    name = 'abgabe_' + filename + '1' + '.csv'\n",
    "    solution.to_csv(name,index=False)\n",
    "    \n",
    "    # Nicilist2\n",
    "    ypred = ypred\n",
    "    for i in range(0,np.shape(ypred)[0]):\n",
    "        if i in nicilist1 or i in nicilist2:\n",
    "            ypred[i] = 3\n",
    "\n",
    "    solution = pd.read_csv('sample.csv')\n",
    "    solution['y'] = ypred\n",
    "    name = 'abgabe_' + filename + '2' + '.csv'\n",
    "    solution.to_csv(name,index=False)\n",
    "    \n",
    "    #Nicilist3\n",
    "    ypred = ypred\n",
    "    for i in range(0,np.shape(ypred)[0]):\n",
    "        if i in nicilist1 or i in nicilist2 or i in nicilist3:\n",
    "            ypred[i] = 3\n",
    "\n",
    "    solution = pd.read_csv('sample.csv')\n",
    "    solution['y'] = ypred\n",
    "    name = 'abgabe_' + filename + '3' + '.csv'\n",
    "    solution.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nici + HRV\n",
    "ypred = pd.read_csv('svmPoly.csv')\n",
    "createClass3files(ypred['y'],'svmPoly')\n",
    "\n",
    "ypred = pd.read_csv('svmRBF.csv')\n",
    "createClass3files(ypred['y'],'svmRBF')\n",
    "\n",
    "ypred = pd.read_csv('randomForest.csv')\n",
    "createClass3files(ypred['y'],'randomForest')\n",
    "\n",
    "ypred = pd.read_csv('gradientBoost.csv')\n",
    "createClass3files(ypred['y'],'gradientBoost')\n",
    "\n",
    "# Nici + Mo + HRV\n",
    "ypred = pd.read_csv('svmPolyAll.csv')\n",
    "createClass3files(ypred['y'],'svmPolyAll')\n",
    "\n",
    "ypred = pd.read_csv('svmRBFAll.csv')\n",
    "createClass3files(ypred['y'],'svmRBFAll')\n",
    "\n",
    "ypred = pd.read_csv('randomForestAll.csv')\n",
    "createClass3files(ypred['y'],'randomForestAll')\n",
    "\n",
    "ypred = pd.read_csv('gradientBoostAll.csv')\n",
    "createClass3files(ypred['y'],'gradientBoostAll')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
